{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORHpMF3d5pql8vOzVn/Jvw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirMotefaker/Create-your-own-ChatGPT/blob/main/Create_your_own_ChatGPT_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "- ChatGPT (Chat Generative Pre-trained Transformer) is an AI-powered chatbot created by [OpenAI](https://openai.com/) that enables users to have highly sophisticated, human-like conversations. The language model is capable of answering questions and assist in various tasks, including writing emails, essays, and code. Due to its dialogue design, ChatGPT is capable of answering follow-up questions, acknowledging errors, questioning incorrect assumptions, and declining inappropriate requests.\n",
        "\n",
        "- The ChatGPT model was fine-tuned from a model in the GPT-3.5 series, which completed its training in early 2022. The ChatGPT as well as the related GPT-3.5 models were trained on a high-performance Azure AI supercomputing infrastructure.\n",
        "\n",
        "- While ChatGPT possesses many strengths, being a generalized model, it may not always be the most effective solution for narrower, more specialized topics with limited training data available. Moreover, the dialog interface has not yet been made available by OpenAI for businesses to integrate.\n",
        "\n",
        "[OpenAI Python Library Repo](https://github.com/openai/openai-python)\n",
        "\n",
        "[OpenAI Python Library Website](https://platform.openai.com/docs/libraries)"
      ],
      "metadata": {
        "id": "bRez2FOKYnOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Large language models (LLM)\n",
        "- Large language models (LLM) currently apply across natural language specific implementations, such as machine translation, speech recognition, and text generation. LLMs are trained on large amounts of data and can be composed of many layers.\n",
        "\n",
        "- Large language models (LLMs) represent a major advancement in AI, with the promise of transforming domains through learned knowledge. LLM sizes have been increasing 10X every year for the last few years, and as these models grow in complexity and size, so do their capabilities.\n",
        "\n",
        "\n",
        "### Example 1: \n",
        "- Google Translate is a large language model that uses artificial intelligence to translate one language into another. It supports over 100 languages and can handle multiple dialects of each language. Foundationally, Google Translate’s use of LLM informs the translations between languages. Furthermore, because many users interact with it on a daily basis, the model is continuously updated.\n",
        "\n",
        "### Example 2: \n",
        "- Generative Adversarial Networks have been used to create fake images that are indistinguishable from real ones — even by humans.\n",
        "\n",
        "### Example 3: \n",
        "- Consider OpenAI’s GPT, a transformational capability as an LLM for the industry, allowing the user to interact with it for language-specific use cases.\n",
        "\n",
        "\n",
        "## Challenges of Large Language Models\n",
        "- Scaling and maintaining large language models can be difficult and expensive.\n",
        "\n",
        "- Building a foundational large language model often requires months of training time and millions of dollars.\n",
        "\n",
        "- And because LLMs require a significant amount of training data, developers and enterprises can find it a challenge to access large-enough datasets.\n",
        "\n",
        "- Due to the scale of large language models, deploying them requires technical expertise, including a strong understanding of deep learning, transformer models and distributed software and hardware.\n",
        "\n",
        "- Many leaders in tech are working to advance development and build resources that can expand access to large language models, allowing consumers and enterprises of all sizes to reap their benefits.\n"
      ],
      "metadata": {
        "id": "lYS56al6hsBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-3\n",
        "- In 2020, the Generative Pre-trained Transformer 3 (GPT-3) was introduced as an autoregressive language model capable to generate high-quality text that resembles human writing. The GPT-3 is the third generation of the GPT language models made available by OpenAI.\n",
        "\n",
        "- By providing an initial prompt as input, GPT-3 has the ability to produce a continuation of the text that follows the style and structure of the input prompt. The model is capable of performing a range of tasks, including but not limited to, text classification, question answering, text generation, text summarization, named-entity recognition, and language translation."
      ],
      "metadata": {
        "id": "5f_bZ-6AwnwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT Methods\n",
        "\n",
        "- We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as [InstructGPT](https://openai.com/blog/instruction-following/), but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides—the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.\n",
        "\n",
        "- Reinforcement learning from human feedback enhances the RL agent's training by including humans in the training process. This helps account for the elements that can't be measured in the reward system.\n",
        "\n",
        "- To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using [Proximal Policy Optimization](https://openai.com/blog/openai-baselines-ppo/). We performed several iterations of this process.\n",
        "\n",
        "- ChatGPT is fine-tuned from a model in the GPT-3.5 series, which finished training in early 2022. You can learn more about the 3.5 series [here](https://beta.openai.com/docs/model-index-for-researchers). ChatGPT and GPT 3.5 were trained on an Azure AI supercomputing infrastructure."
      ],
      "metadata": {
        "id": "2vJdWlR95WRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT Limitations\n",
        "- ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: during RL training, there’s currently no source of truth; training the model to be more cautious causes it to decline questions that it can answer correctly; and supervised training misleads the model because the ideal answer [depends on what the model knows](https://www.alignmentforum.org/posts/BgoKdAzogxmgkuuAt/behavior-cloning-is-miscalibrated), rather than what the human demonstrator knows.\n",
        "\n",
        "- ChatGPT is sensitive to tweaks to the input phrasing or attempting the same prompt multiple times. For example, given one phrasing of a question, the model can claim to not know the answer, but given a slight rephrase, can answer correctly.\n",
        "\n",
        "- The model is often excessively verbose and overuses certain phrases, such as restating that it’s a language model trained by OpenAI. These issues arise from biases in the training data (trainers prefer longer answers that look more comprehensive) and well-known over-optimization issues.\n",
        "\n",
        "- Ideally, the model would ask clarifying questions when the user provided an ambiguous query. Instead, our current models usually guess what the user intended.\n",
        "\n",
        "- While we’ve made efforts to make the model refuse inappropriate requests, it will sometimes respond to harmful instructions or exhibit biased behavior. We’re using the [Moderation API](https://openai.com/blog/new-and-improved-content-moderation-tooling/) to warn or block certain types of unsafe content, but we expect it to have some false negatives and positives for now. We’re eager to collect user feedback to aid our ongoing work to improve this system."
      ],
      "metadata": {
        "id": "-mbNzr235-zQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model index\n",
        "- Our models are used for both research purposes and developer use cases in production. Researchers often learn about our models from papers that we have published, but there is often not a perfect match between what is available in the OpenAI API and what is published in a paper.\n",
        "\n",
        "- The purpose of this page is to help clarify:\n",
        "\n",
        "  - Some of the differences in the ways that our models are trained, which impacts the comparisons that can be made between models, and various evaluation results.\n",
        "  - The differences between various model series, such as GPT 3.5 and InstructGPT.\n",
        "  - Which if any of the models available in the API today match with a model in a paper. In some cases, there might not be a match."
      ],
      "metadata": {
        "id": "S2MyxS5K8NZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models referred to as \"GPT 3.5\"\n",
        "- GPT-3.5 series is a series of models that was trained on a blend of text and code from before Q4 2021. The following models are in the GPT-3.5 series:\n",
        "\n",
        "  - code-davinci-002 is a base model, so good for pure code-completion tasks\n",
        "  - text-davinci-002 is an InstructGPT model based on code-davinci-002\n",
        "  - text-davinci-003 is an improvement on text-davinci-002"
      ],
      "metadata": {
        "id": "LDCtmJGy7-LR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING METHOD\tMODELS\n",
        "  - SFT\n",
        "    - Supervised fine-tuning on human demonstrations\tdavinci-instruct-beta1\n",
        "\n",
        "  - FeedME\n",
        "    - Supervised fine-tuning on human-written demonstrations and on model samples rated 7/7 by human labelers on an overall quality score\ttext-davinci-001, text-davinci-002, text-curie-001, text-babbage-001\n",
        "\n",
        "  - PPO\n",
        "    - Reinforcement learning with reward models trained from comparisons by humans\ttext-davinci-003\n",
        "\n",
        "#### The SFT and PPO models are trained similarly to the ones from the [InstructGPT paper](https://arxiv.org/abs/2203.02155). FeedME (short for \"feedback made easy\") models are trained by distilling the best completions from all of our models. Our models generally used the best available datasets at the time of training, and so different engines using the same training methodology might be trained on different data."
      ],
      "metadata": {
        "id": "65VYUCCt9c-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Model index for researchers](https://platform.openai.com/docs/model-index-for-researchers)"
      ],
      "metadata": {
        "id": "ZJ5XDVdpDJpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n",
        "\n",
        "- Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent."
      ],
      "metadata": {
        "id": "yS1cPd8dIWAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advantages and Disadvantages of ChatGPT\n",
        "\n",
        "#### Advantages:\n",
        "1. Imitates Human Conversation\n",
        "    - The core feature of ChatGPT centers on providing human-like conversation based on user-placed queries or commands. It is generally similar to virtual assistant technologies and software applications such as Siri from Apple and Alexa from Amazon. However, considering its capabilities, it mimics real-life conversation because it is based on more advanced supervised learning and reinforcement learning using large language models.\n",
        "    \n",
        "\n",
        "2. Built Based on GPT-3 Model\n",
        "    - GPT-3 or Generative Pre-trained Transformer 3 is an autoregressive language and language prediction model developed by OpenAI. It is the largest non-sparse language model and has been considered one of the most important AI systems ever produced. The quality of texts it generates makes it difficult to ascertain whether or not it is written by a human.\n",
        "    \n",
        "\n",
        "3. Expansive Applications and Benefits\n",
        "    - The chatbot is versatile. It can write outputs similar to commercial AI copywriters. Experiments have shown that it can even compose music and produce works of fiction such as short stories. It can help content creators or technical writers produce an outline. The chatbot can also summarize, digest, and explain large bodies of text. Another interesting application of ChatGPT is that it can also write and debug computer programs.\n",
        "    \n",
        "\n",
        "4. Open For Further Fine-Tuning\n",
        "    - Another advantage of ChatGPT is that its responses and overall performance can be fine-tuned. It banks on existing large language models while also having room for further improvements through active training using supervised learning and reinforcement learning. A user can upvote or downvote a particular response while also providing additional feedback.\n",
        "    \n",
        "\n",
        "#### Disadvantages:\n",
        "1. Inaccuracies and Ambiguities\n",
        "    - One of the biggest criticisms and limitations of ChatGPT is that it sometimes tends to produce texts that sound plausible or convincing but are incorrect or nonsensical under the surface. This phenomenon is called “hallucination” and it is common in language models. Furthermore, when it comes to obtaining information, it does not provide references or citations. Using this chatbot alone for research purposes and electronic trailing is not ideal.\n",
        "    \n",
        "\n",
        "2. Limited Knowledge of Recent Events\n",
        "    - The version launched in November 2022 can only provide information about events occurring in 2021 and earlier. It will soon provide more recent events as it continues to feed on data based on human-generated texts. Nevertheless, considering this drawback, users should keep in mind that it has limited knowledge of facts because it uses datasets that are not updated.\n",
        "    \n",
        "\n",
        "3. Ethical Issues and Concerns\n",
        "    - Another disadvantage of ChatGPT is that it has been subjected to scrutiny. Several educational institutions have banned its use. Researchers and creatives have worried about copyright infringement because its outputs are based on human-generated texts. It also raises the question of whether it is ethical to use it as a substitute for services that require human interactions such as customer service representation and even therapeutic counseling.\n",
        "    \n",
        "\n",
        "4. Other Possible Legal Implications\n",
        "    - GPT was built with data from the Common Crawl dataset which contains copyrighted materials from publishing companies and individual authors and researchers. Experts have also warned that AI-based applications can be used for cybercriminal activities. ChatGPT and other derivatives face legal uncertainties and possible compliance costs.\n"
      ],
      "metadata": {
        "id": "yqz-7w2nIdkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT — Release Notes\n",
        "\n",
        "- Release Notes (Feb 13)\n",
        "    - We’ve made several updates to ChatGPT! Here's what's new:\n",
        "\n",
        "    - We’ve updated performance of the ChatGPT model on our free plan in order to serve more users.\n",
        "\n",
        "    - Based on user feedback, we are now defaulting Plus users to a faster version of ChatGPT, formerly known as “Turbo”. We’ll keep the previous version around for a while.\n",
        "\n",
        "    - We rolled out the ability to purchase [ChatGPT Plus](https://openai.com/blog/chatgpt-plus/) internationally.\n",
        "    \n",
        "## [The latest update for ChatGPT](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)"
      ],
      "metadata": {
        "id": "rRzJ4BP5h54p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install library\n",
        "\n",
        "- [Libraries](https://platform.openai.com/docs/libraries)"
      ],
      "metadata": {
        "id": "He-5tPSJXqmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww6doUjAY5xD",
        "outputId": "b95e9790-0241-4a33-fea2-4d46c5a4f9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=eabef0e1d16bbeb2e7b05449159fbae209c7f36c1c89a4a9b4a1f269a662ded1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upgrade library\n",
        "- If needed upgrade openai library."
      ],
      "metadata": {
        "id": "4ruY6lfrZKFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9JWL7FXZGkU",
        "outputId": "8d23f3fc-76c3-45ec-8915-3a523a80ac3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.26.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import openai library"
      ],
      "metadata": {
        "id": "43n-YHVXhx7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "Oq3JjiLhik4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the OpenAI API client"
      ],
      "metadata": {
        "id": "UHe9u862lEG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- How to get Your Secret API?\n",
        "\n",
        "  1. Go to [OpenAI API](https://openai.com/api/)\n",
        "  2. Click on signup\n",
        "  3. Complete SignUp with google or email or microsoft\n",
        "  4. Now, login and go to [OpenAI Platform](https://platform.openai.com/)\n",
        "  5. Click on Personal and then click on View API keys\n",
        "  6. Now, click on ‘Create new secret key‘ and copy the secret key\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "llJ2Yj7EmYwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# openai.api_key = \"your secret API Key\"\n",
        "openai.api_key = \"----\""
      ],
      "metadata": {
        "id": "njhqI3ykrTbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this loop will let us ask questions continuously\n",
        "\n",
        "while True:\n",
        "    \n",
        "    # Set up the model and prompt\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    \n",
        "    prompt = input('Enter new prompt: ')\n",
        "\n",
        "    if 'exit' in prompt or 'quit' in prompt:\n",
        "        break\n",
        "\n",
        "    # Generate a response\n",
        "    # given the most recent context (4096 characters)\n",
        "    # continue the text up to 2048 tokens ~ 8192 charaters\n",
        "    completion = openai.Completion.create(\n",
        "        engine=model_engine,\n",
        "        prompt=prompt,\n",
        "        max_tokens=1024,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "    \n",
        "    # extracting useful part of response\n",
        "    response = completion.choices[0].text\n",
        "    \n",
        "    # printing response\n",
        "    print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi6Y6ryusKR8",
        "outputId": "52cc793d-618f-4595-e59c-4b69df4a5a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter new prompt: Which is the largest country by area in the world?\n",
            "\n",
            "\n",
            "Russia is the largest country in the world by area, with a total landmass of 17,098,242 square kilometers (6,601,668 square miles).\n",
            "Enter new prompt: population to top 5 countries\n",
            "\n",
            "\n",
            "1. China - 1.4 billion\n",
            "2. India - 1.3 billion\n",
            "3. United States - 330 million\n",
            "4. Indonesia - 270 million\n",
            "5. Brazil - 210 million\n",
            "Enter new prompt: top 5 football players in the world\n",
            "\n",
            "\n",
            "1. Lionel Messi\n",
            "2. Cristiano Ronaldo\n",
            "3. Neymar Jr.\n",
            "4. Robert Lewandowski\n",
            "5. Kylian Mbappe\n",
            "Enter new prompt: exit\n"
          ]
        }
      ]
    }
  ]
}