{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/create-your-own-chatgpt?scriptVersionId=120149164\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Introduction\n- ChatGPT (Chat Generative Pre-trained Transformer) is an AI-powered chatbot created by [OpenAI](https://openai.com/) that enables users to have highly sophisticated, human-like conversations. The language model is capable of answering questions and assist in various tasks, including writing emails, essays, and code. Due to its dialogue design, ChatGPT is capable of answering follow-up questions, acknowledging errors, questioning incorrect assumptions, and declining inappropriate requests.\n\n- The ChatGPT model was fine-tuned from a model in the GPT-3.5 series, which completed its training in early 2022. The ChatGPT as well as the related GPT-3.5 models were trained on a high-performance Azure AI supercomputing infrastructure.\n\n- ChatGPT: Optimizing Language Models for Dialogue.\n\n- While ChatGPT possesses many strengths, being a generalized model, it may not always be the most effective solution for narrower, more specialized topics with limited training data available. Moreover, the dialog interface has not yet been made available by OpenAI for businesses to integrate.\n\n[OpenAI Python Library Repo](https://github.com/openai/openai-python)\n\n[OpenAI Python Library Website](https://platform.openai.com/docs/libraries)","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle"}},{"cell_type":"markdown","source":"# GPT-3\n- In 2020, the Generative Pre-trained Transformer 3 (GPT-3) was introduced as an autoregressive language model capable to generate high-quality text that resembles human writing. The GPT-3 is the third generation of the GPT language models made available by OpenAI.\n\n- By providing an initial prompt as input, GPT-3 has the ability to produce a continuation of the text that follows the style and structure of the input prompt. The model is capable of performing a range of tasks, including but not limited to, text classification, question answering, text generation, text summarization, named-entity recognition, and language translation.","metadata":{}},{"cell_type":"markdown","source":"# ChatGPT Methods\n\n- We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as [InstructGPT](https://openai.com/blog/instruction-following/), but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides—the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.\n\n- Reinforcement learning from human feedback enhances the RL agent's training by including humans in the training process. This helps account for the elements that can't be measured in the reward system.\n\n- To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using [Proximal Policy Optimization](https://openai.com/blog/openai-baselines-ppo/). We performed several iterations of this process.\n\n- ChatGPT is fine-tuned from a model in the GPT-3.5 series, which finished training in early 2022. You can learn more about the 3.5 series [here](https://beta.openai.com/docs/model-index-for-researchers). ChatGPT and GPT 3.5 were trained on an Azure AI supercomputing infrastructure.","metadata":{}},{"cell_type":"markdown","source":"# ChatGPT Limitations\n- ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: during RL training, there’s currently no source of truth; training the model to be more cautious causes it to decline questions that it can answer correctly; and supervised training misleads the model because the ideal answer [depends on what the model knows](https://www.alignmentforum.org/posts/BgoKdAzogxmgkuuAt/behavior-cloning-is-miscalibrated), rather than what the human demonstrator knows.\n\n- ChatGPT is sensitive to tweaks to the input phrasing or attempting the same prompt multiple times. For example, given one phrasing of a question, the model can claim to not know the answer, but given a slight rephrase, can answer correctly.\n\n- The model is often excessively verbose and overuses certain phrases, such as restating that it’s a language model trained by OpenAI. These issues arise from biases in the training data (trainers prefer longer answers that look more comprehensive) and well-known over-optimization issues.\n\n- Ideally, the model would ask clarifying questions when the user provided an ambiguous query. Instead, our current models usually guess what the user intended.\n\n- While we’ve made efforts to make the model refuse inappropriate requests, it will sometimes respond to harmful instructions or exhibit biased behavior. We’re using the [Moderation API](https://openai.com/blog/new-and-improved-content-moderation-tooling/) to warn or block certain types of unsafe content, but we expect it to have some false negatives and positives for now. We’re eager to collect user feedback to aid our ongoing work to improve this system.","metadata":{}},{"cell_type":"markdown","source":"# Model index\n- Our models are used for both research purposes and developer use cases in production. Researchers often learn about our models from papers that we have published, but there is often not a perfect match between what is available in the OpenAI API and what is published in a paper.\n\n- The purpose of this page is to help clarify:\n\n  - Some of the differences in the ways that our models are trained, which impacts the comparisons that can be made between models, and various evaluation results.\n  - The differences between various model series, such as GPT 3.5 and InstructGPT.\n  - Which if any of the models available in the API today match with a model in a paper. In some cases, there might not be a match.","metadata":{}},{"cell_type":"markdown","source":"# Models referred to as \"GPT 3.5\"\n- GPT-3.5 series is a series of models that was trained on a blend of text and code from before Q4 2021. The following models are in the GPT-3.5 series:\n\n  - code-davinci-002 is a base model, so good for pure code-completion tasks\n  - text-davinci-002 is an InstructGPT model based on code-davinci-002\n  - text-davinci-003 is an improvement on text-davinci-002","metadata":{}},{"cell_type":"markdown","source":"# TRAINING METHOD\tMODELS\n  - SFT\n    - Supervised fine-tuning on human demonstrations\tdavinci-instruct-beta1\n\n  - FeedME\n    - Supervised fine-tuning on human-written demonstrations and on model samples rated 7/7 by human labelers on an overall quality score\ttext-davinci-001, text-davinci-002, text-curie-001, text-babbage-001\n\n  - PPO\n    - Reinforcement learning with reward models trained from comparisons by humans\ttext-davinci-003\n\n#### The SFT and PPO models are trained similarly to the ones from the [InstructGPT paper](https://arxiv.org/abs/2203.02155). FeedME (short for \"feedback made easy\") models are trained by distilling the best completions from all of our models. Our models generally used the best available datasets at the time of training, and so different engines using the same training methodology might be trained on different data.","metadata":{}},{"cell_type":"markdown","source":"### [Model index for researchers](https://platform.openai.com/docs/model-index-for-researchers)","metadata":{}},{"cell_type":"markdown","source":"### [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n\n- Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.","metadata":{}},{"cell_type":"markdown","source":"# Install library\n\n- [Libraries](https://platform.openai.com/docs/libraries)","metadata":{}},{"cell_type":"code","source":"pip install openai","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:08:13.017565Z","iopub.execute_input":"2023-02-24T06:08:13.018024Z","iopub.status.idle":"2023-02-24T06:08:41.382433Z","shell.execute_reply.started":"2023-02-24T06:08:13.017941Z","shell.execute_reply":"2023-02-24T06:08:41.381161Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nCollecting openai\n  Using cached openai-0.26.5.tar.gz (55 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.1.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.1)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.11)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.1.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.7.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nBuilding wheels for collected packages: openai\n  Building wheel for openai (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67596 sha256=c3221e0b2863ab6a3e2333d9b6001934d24e236d17327e5c34e666fbf0fdbaf5\n  Stored in directory: /root/.cache/pip/wheels/71/cc/39/e215726261759bc158d31178f0ff0adab8111cc1b1d2806ce4\nSuccessfully built openai\nInstalling collected packages: openai\nSuccessfully installed openai-0.26.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### If needed upgrade openai library.","metadata":{}},{"cell_type":"markdown","source":"# Upgrade library","metadata":{}},{"cell_type":"code","source":"pip install --upgrade openai","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:08:41.385013Z","iopub.execute_input":"2023-02-24T06:08:41.385374Z","iopub.status.idle":"2023-02-24T06:08:50.334904Z","shell.execute_reply.started":"2023-02-24T06:08:41.385343Z","shell.execute_reply":"2023-02-24T06:08:50.333916Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRequirement already satisfied: openai in /opt/conda/lib/python3.7/site-packages (0.26.5)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.1)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.11)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.1.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.7.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import openai library","metadata":{}},{"cell_type":"code","source":"import openai","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:08:50.336635Z","iopub.execute_input":"2023-02-24T06:08:50.337029Z","iopub.status.idle":"2023-02-24T06:08:50.466586Z","shell.execute_reply.started":"2023-02-24T06:08:50.336996Z","shell.execute_reply":"2023-02-24T06:08:50.46506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Set up the OpenAI API client","metadata":{}},{"cell_type":"markdown","source":"- How to get Your Secret API?\n\n  1. Go to [OpenAI API](https://openai.com/api/)\n  2. Click on signup\n  3. Complete SignUp with google or email or microsoft\n  4. Now, login and go to [OpenAI Platform](https://platform.openai.com/)\n  5. Click on Personal and then click on View API keys\n  6. Now, click on ‘Create new secret key‘ and copy the secret key","metadata":{}},{"cell_type":"code","source":"# openai.api_key = \"your secret API Key\"\nopenai.api_key = \"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\"","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:08:50.468766Z","iopub.execute_input":"2023-02-24T06:08:50.46937Z","iopub.status.idle":"2023-02-24T06:08:50.475258Z","shell.execute_reply.started":"2023-02-24T06:08:50.469332Z","shell.execute_reply":"2023-02-24T06:08:50.473913Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# this loop will let us ask questions continuously\n\nwhile True:\n    \n    # Set up the model and prompt\n    model_engine = \"text-davinci-003\"\n    \n    prompt = input('Enter new prompt: ')\n\n    if 'exit' in prompt or 'quit' in prompt:\n        break\n\n    # Generate a response\n    # given the most recent context (4096 characters)\n    # continue the text up to 2048 tokens ~ 8192 charaters\n    completion = openai.Completion.create(\n        engine=model_engine,\n        prompt=prompt,\n        max_tokens=1024,\n        n=1,\n        stop=None,\n        temperature=0.5,\n    )\n    \n    # extracting useful part of response\n    response = completion.choices[0].text\n    \n    # printing response\n    print(response)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T06:08:50.476204Z","iopub.execute_input":"2023-02-24T06:08:50.4765Z","iopub.status.idle":"2023-02-24T06:11:37.133076Z","shell.execute_reply.started":"2023-02-24T06:08:50.476476Z","shell.execute_reply":"2023-02-24T06:11:37.131682Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter new prompt:  Which is the largest country by area in the world?\n"},{"name":"stdout","text":"\n\nRussia is the largest country by area in the world, with an area of 17,098,242 square kilometers.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter new prompt:  population to top 5 countries\n"},{"name":"stdout","text":"\n\n1. China - 1.4 billion\n2. India - 1.3 billion\n3. United States - 329 million\n4. Indonesia - 270 million\n5. Brazil - 211 million\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter new prompt:  top 5 football players in the world\n"},{"name":"stdout","text":"\n\n1. Lionel Messi\n2. Cristiano Ronaldo\n3. Neymar Jr.\n4. Kylian Mbappe\n5. Kevin De Bruyne\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter new prompt:  exit\n"}]}]}